# -*- mode: Snakemake -*-
#
# Rules for de novo assembly using SPAdes and post-assembly assessments

from sunbeamlib import samtools
import glob
import pysam
import re
import yaml

ruleorder: run_spades_paired > run_spades_unpaired

rule run_spades_paired:
    input:
       r1 = str(QC_FP/'decontam'/'{sample}_1.fastq.gz'),
       r2 = str(QC_FP/'decontam'/'{sample}_2.fastq.gz')
    output:
       str(ASSEMBLY_FP/'spades_bins'/'{sample}'/'{sample}_assembled_contigs.fna')
    threads: 
      Cfg['sbx_SPARCQ']['threads']
    params: 
       outdir = str(ASSEMBLY_FP/'spades'/'{sample}'),
       mk_dir = str(ASSEMBLY_FP/'spades_bins'/'{sample}'),
       copy_from = str(ASSEMBLY_FP/'spades'/'{sample}'/'contigs.fasta')
    shell:
       """
       spades.py -1 {input.r1} -2 {input.r2} -o {params.outdir} -t {threads} -m 100 && \
       mkdir -p {params.mk_dir} && \
       cp {params.copy_from} {output}
       """

rule run_spades_unpaired:
    input:
       r1 = str(QC_FP/'decontam'/'{sample}_1.fastq.gz')
    output:
       str(ASSEMBLY_FP/'spades_bins'/'{sample}'/'{sample}_assembled_contigs.fna')
    threads:
      Cfg['sbx_SPARCQ']['threads']
    params:
       outdir = str(ASSEMBLY_FP/'spades'/'{sample}'),
       mk_dir = str(ASSEMBLY_FP/'spades_bins'/'sample'),
       copy_from = str(ASSEMBLY_FP/'spades'/'{sample}'/'contigs.fasta')
    shell:
       """
       spades.py --s 1 {input.r1} -o {params.outdir} -t {threads} -m 100 && \
       mkdir -p {params.mk_dir} && \
       cp {params.copy_from} {output}
       """

rule prokka:
    input:
       str(ASSEMBLY_FP/'spades_bins'/'{sample}'/'{sample}_assembled_contigs.fna')
    output:
       str(ANNOTATION_FP/'prokka'/'{sample}'/'{sample}.ffn')
    params:
       outdir = str(ANNOTATION_FP/'prokka'/'{sample}')
    conda:
       "sbx_SPARCQ_conda_env.yml"
    shell:
       """
       prokka --compliant --centre CHOP --outdir {params.outdir} --locustag {wildcards.sample} --prefix {wildcards.sample} --force {input} 
       """

checkm_yml = Cfg['sbx_SPARCQ'].get('checkm_yml')
if checkm_yml:
   with open(checkm_yml, 'r') as file:
      checkm_params = yaml.load(file, Loader = yaml.FullLoader)
      rank_yml = checkm_params['rank']
      taxon_yml = checkm_params['taxon']

rule checkm_tree:
    input:
       str(ASSEMBLY_FP/'spades_bins'/'{sample}'/'{sample}_assembled_contigs.fna')
    output:
       str(ASSEMBLY_FP/'checkm_output'/'tree_output'/'{sample}'/'tree_done')
    threads:
       Cfg['sbx_SPARCQ']['threads']
    params:
       bins = str(ASSEMBLY_FP/'spades_bins'/'{sample}'),
       tree_output = str(ASSEMBLY_FP/'checkm_output'/'tree_output'/'{sample}')
    run:
       if checkm_yml and wildcards.sample in taxon_yml:
          taxon = str(taxon_yml[wildcards.sample])
          rank = str(rank_yml[wildcards.sample])
          shell("""
          checkm taxonomy_wf -t {threads} {rank} '{taxon}' {params.bins} {params.tree_output} && \
          touch {output}
          """)
       else:
          shell("""
          checkm lineage_wf -t {threads} {params.bins} {params.tree_output} && \
          touch {output}
          """)

rule checkm_plot:
    input:
       str(ASSEMBLY_FP/'checkm_output'/'tree_output'/'{sample}'/'tree_done')
    output:
       str(ASSEMBLY_FP/'checkm_output'/'plots_output'/'{sample}'/'plots_done')
    params:
       bins = str(ASSEMBLY_FP/'spades_bins'/'{sample}'),
       plots_output = str(ASSEMBLY_FP/'checkm_output'/'plots_output'/'{sample}'),
       tree_output = str(ASSEMBLY_FP/'checkm_output'/'tree_output'/'{sample}')
    run:
       shell("""
       checkm nx_plot {params.bins} {params.plots_output} && \
       checkm gc_plot {params.bins} {params.plots_output} 95 && \
       checkm coding_plot {params.tree_output} {params.bins} {params.plots_output} 95 && \
       checkm marker_plot --dpi 300 --image_type pdf {params.tree_output} {params.bins} {params.plots_output} && \
       touch {output}
       """)

rule checkm_summary:
    input:
       str(ASSEMBLY_FP/'checkm_output'/'tree_output'/'{sample}'/'tree_done')
    output:
       str(ASSEMBLY_FP/'checkm_output'/'summary'/'{sample}'/'extended_summary.tsv')
    params:
       tree_output = str(ASSEMBLY_FP/'checkm_output'/'tree_output'/'{sample}')
    run:
       if checkm_yml and wildcards.sample in taxon_yml:
          taxon = str(taxon_yml[wildcards.sample])
          shell("""
          checkm qa --out_format 2 --tab_table --file {output} "{params.tree_output}/{taxon}.ms" {params.tree_output}
          """)
       else:
          shell("""
          checkm qa --out_format 2 --tab_table --file {output} "{params.tree_output}/lineage.ms" {params.tree_output}
          """)

taxid_yml = Cfg['sbx_SPARCQ'].get('taxid_yml')
if taxid_yml:
   with open(taxid_yml, 'r') as file2:
      ncbi_params = yaml.load(file2, Loader = yaml.FullLoader)
      NCBI_ID = ncbi_params['NCBI_ID']

rule quast:
    input:
       str(ASSEMBLY_FP/'spades_bins'/'{sample}'/'{sample}_assembled_contigs.fna')
    output:
       str(ASSEMBLY_FP/'quast_output'/'{sample}'/'icarus.html')
    params:
       quast_output = str(ASSEMBLY_FP/'quast_output'/'{sample}')
    run:
       if taxid_yml and wildcards.sample in NCBI_ID:
          shell("""
          ncbi-genome-download -F fasta,gff -t NCBI_ID[wildcards.sample] -o {params.quast_output} all
          """)
          ncbi_fna=glob.glob(params.quast_output+'/**/*.fna.gz', recursive = True)[0]
          ncbi_gff=glob.glob(params.quast_output+'/**/*.gff.gz', recursive = True)[0]
          shell("""
          quast.py {input} -r {ncbi_fna} -g {ncbi_gff} -o {params.quast_output}
          """)
       else:
          shell("""
          quast.py {input} -o {params.quast_output}
          """)
   
rule index_assembled_genomes:
    input:
        str(ASSEMBLY_FP/'spades_bins'/'{sample}'/'{sample}_assembled_contigs.fna')
    output:
        str(ASSEMBLY_FP/'read_mapping'/'{sample}'/'bwa'/'{sample}_assembled_contigs.fna.amb')
    params:
        bwa_dir = str(ASSEMBLY_FP/'read_mapping'/'{sample}'/'bwa'),
        bwa_sample = str(ASSEMBLY_FP/'read_mapping'/'{sample}'/'bwa'/'{sample}_assembled_contigs.fna')
    shell:
        "mkdir -p {params.bwa_dir} && \
         cp {input} {params.bwa_dir} && \
         cd {params.bwa_dir} && \
         bwa index {params.bwa_sample}"

rule align_2_genome:
    input:
        reads = expand(
            str(QC_FP/'decontam'/'{{sample}}_{rp}.fastq.gz'),
            rp = Pairs),
        index = str(ASSEMBLY_FP/'read_mapping'/'{sample}'/'bwa'/'{sample}_assembled_contigs.fna.amb')
    output:
        temp(str(ASSEMBLY_FP/'read_mapping'/'{sample}'/'bwa'/'intermediates'/'{sample}.sam'))
    threads:
        Cfg['sbx_SPARCQ']['threads']
    params:
        str(ASSEMBLY_FP/'read_mapping'/'{sample}'/'bwa'/'{sample}_assembled_contigs.fna')
    shell:
        """
        bwa mem -M -t {threads} \
        {params} \
        {input.reads} -o {output}
        """

rule assembly_samtools_convert:
    input:
        str(ASSEMBLY_FP/'read_mapping'/'{sample}'/'bwa'/'intermediates'/'{sample}.sam')
    output:
        str(ASSEMBLY_FP/'read_mapping'/'{sample}'/'bwa'/'{sample}.bam')
    threads:
        Cfg['sbx_SPARCQ']['threads']
    shell:
        """
        samtools view -@ {threads} -b {input} | \
        samtools sort -@ {threads} > {output}
        """

rule index_samtools:
    input: str(ASSEMBLY_FP/'read_mapping'/'{sample}'/'bwa'/'{sample}.bam')
    output: str(ASSEMBLY_FP/'read_mapping'/'{sample}'/'bwa'/'{sample}.bam.bai')
    shell: "samtools index {input} {output}"

rule samtools_get_coverage_filtered:
    input:
        str(ASSEMBLY_FP/'read_mapping'/'{sample}'/'bwa'/'{sample}.bam')
    output:
        str(ASSEMBLY_FP/'read_mapping'/'{sample}'/'genome_coverage_{sample}.csv')
    run:
        samtools.get_coverage_stats(
            wildcards.sample, input[0], wildcards.sample, output[0])

def _sorted_csvs(w):
    pattern = str(ASSEMBLY_FP/'read_mapping'/'{sample}'/'genome_coverage_{sample}.csv')
    paths = sorted(expand(pattern, sample=Samples.keys()))
    return(paths)

rule summarize_assembly_coverage:
    input: _sorted_csvs
    output:
        str(ASSEMBLY_FP/'read_mapping'/'all_coverage.csv')
    shell: "(head -n 1 {input[0]}; tail -q -n +2 {input}) > {output}"

rule samtools_summarize_num_mapped_reads:
    input:
        str(ASSEMBLY_FP/'read_mapping'/'{sample}'/'bwa'/'{sample}.bam')
    output:
        str(ASSEMBLY_FP/'read_mapping'/'{sample}'/'numReads_{sample}.csv')
    shell:
        """
        samtools idxstats {input} | (sed 's/^/{wildcards.sample}\t/') > {output}
        """

def _numReads(w):
    pattern = str(ASSEMBLY_FP/'read_mapping'/'{sample}'/'numReads_{sample}.csv')
    paths = sorted(expand(pattern, sample=Samples.keys()))
    return(paths)

rule samtools_summarize_numReads:
    input:
        _numReads
    output:
        str(ASSEMBLY_FP/'read_mapping'/'all_numReads.csv')
    shell: "(cat {input}) > {output}"

def sliding_window_coverage(genome, bamfile, sample, output_fp, N, sampling):
    print(genome)
    print(bamfile)
    print(sample)
    print(output_fp)
    print(N)
    print(sampling)

    output_rows = []
    args = ["samtools", "depth", "-aa", bamfile]
    p = subprocess.Popen(args, stdout=subprocess.PIPE, universal_newlines=True)
    # Organize into a list of depths for each segment, streaming in text
    reader = csv.reader(p.stdout, delimiter='\t')
    data = {}
    for row in reader:
    	if not data.get(row[0]):
           data[row[0]] = []
    	data[row[0]].append(int(row[2]))

    fields = ['Genome', 'Segment', 'Sample', 'Location', 'Average']
    with open(output_fp, 'w') as f:
        writer = csv.writer(f)
    	writer.writerow(fields)
    	for segment in data.keys():
            if len(data[segment]) > sampling:
               moving_avg = numpy.convolve(data[segment], numpy.ones((N,))/N, mode='full')
               for i,x in enumerate(moving_avg):
                   if (i%sampling == 0): 
                       writer.writerow([genome, segment, sample, i, x])

rule samtools_get_sliding_coverage:
    input:
        str(ASSEMBLY_FP/'read_mapping'/'{sample}'/'bwa'/'{sample}.bam')
    output:
        str(ASSEMBLY_FP/'read_mapping'/'{sample}'/'sliding_coverage_{sample}.csv')
    params:
        window_size = Cfg['sbx_SPARCQ']['window_size'],
        sampling = Cfg['sbx_SPARCQ']['sampling']
    run:
        sliding_window_coverage(wildcards.sample, input[0], wildcards.sample, output[0], params.window_size, params.sampling)

def _sliding_coverage_csvs(w):
    pattern = str(ASSEMBLY_FP/'read_mapping'/'{sample}'/'sliding_coverage_{sample}.csv')
    paths = sorted(expand(pattern, sample=Samples.keys()))
    return(paths)

rule samtools_summarize_sliding_coverage:
    input:
        _sliding_coverage_csvs
    output:
        str(ASSEMBLY_FP/'read_mapping'/'all_sliding_coverage.csv')
    shell: "(head -n 1 {input[0]}; tail -q -n +2 {input}) > {output}"
